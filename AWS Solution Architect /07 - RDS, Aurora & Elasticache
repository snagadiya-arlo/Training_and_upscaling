# Amazon RDS (Relational Database Service)

## Overview

**RDS** stands for **Relational Database Service**

- It's a **managed DB service** for databases that use SQL as a query language
- Allows you to create databases in the cloud that are **managed by AWS**

### Supported Database Engines

- **Postgres**
- **MySQL**
- **MariaDB**
- **Oracle**
- **Microsoft SQL Server**
- **IBM DB2**
- **Aurora** (AWS Proprietary database)

### Detailed Explanation

- RDS (Relational Database Service) is AWS's managed relational database offering
- You can launch databases without worrying about infrastructure tasks like OS installation, patching, backups, scaling, etc.
- RDS supports all major SQL-based relational databases such as PostgreSQL, MySQL, MariaDB, Oracle, MS SQL Server, IBM DB2, and AWS-optimized Aurora
- AWS handles provisioning, updates, management, monitoring, and high availability, so developers can focus only on database usage, not administration

---

## Advantage of using RDS vs deploying DB on EC2

### EC2 Database (Self-Managed)
- You are responsible for everything: OS patching, DB installation, backup setup, failover configuration, storage scaling, etc.

### RDS (AWS Managed)
AWS automates all database management operations:

| Feature | Description |
|---------|-------------|
| **Automated provisioning** | No manual setup ‚Äî RDS creates DB instance, storage, networking automatically |
| **OS patching** | AWS updates OS and DB version during maintenance windows |
| **Continuous backups** | RDS constantly backs up data and allows point-in-time restore, meaning you can restore your DB to an exact past timestamp |
| **Read replicas** | Improve read performance and reduce load from main DB |
| **Multi-AZ failover** | Automatically switches to a standby DB in another availability zone during outages. Ensures high availability |
| **Scaling** | You can increase instance size (compute scaling) and storage (capacity scaling) |
| **Storage backed by EBS** | Solid-state and provisioned IOPS storage types |

### Limitation

‚ùå You **cannot SSH** into RDS as it's a managed service. You only access it at the database level, not the OS level.

---

## RDS ‚Äì Storage Auto Scaling

### How It Works

- RDS continuously monitors available storage
- When database storage reaches a low threshold (default <10%), RDS automatically increases allocated storage
- No need to manually resize disk volumes ‚Äî saves downtime and operations effort
- You must set a **Maximum Storage Threshold**, so RDS knows how far it can scale

### Auto Scaling Triggers

Auto scaling triggers when:
1. Free storage is less than **10%**
2. Condition persists for at least **5 minutes**
3. It has been **6 hours** since last scaling event (to avoid excessive scaling)

### Diagram Flow

Multiple Users ‚Üí Application ‚Üí Amazon RDS ‚Üí Auto-Scaling Storage

**Basically:** Application ‚Üí RDS ‚Üí Auto-Scaling Storage

---

## RDS Read Replicas for Read Scalability

Read replicas are copies of your main RDS database that are used only for **reading/SELECT** queries. They help improve application performance by reducing load from the main (master) database.

**üí° One-liner:** Read Replicas improve read performance and scalability.

### Details

- You can create up to **15 read replicas** from a single RDS instance
- These replicas can be in:
  - Same Availability Zone (AZ)
  - Cross-AZ
  - Cross-Region (useful for global applications)
- Replication is **ASYNC**, meaning writes go to the master first, and replicas eventually catch up
  - So, replicas may have slight replication delays
- Replicas can later be **promoted** to a standalone database, important for disaster scenarios or migrations
- Applications must change their connection string to use replicas for reads

### Diagram Flow

Application ‚Üí Writes to Main RDS (M - Master)
           ‚Üì
        Async Replication
           ‚Üì
    Multiple Replicas (R)
           ‚Üì
   Reads directed to replicas

---

## RDS Read Replicas ‚Äî Use Cases

Read replicas allow offloading heavy read workloads from the main DB.

**üí° One-liner:** Use read replicas for analytics/reporting without affecting production.

### Details

- **Production DB** handles regular application queries
- If you want to run heavy analytics or reporting, you can use a **read replica**
- This way, production DB is not overloaded
- Read Replicas are used for **SELECT statements only** (no INSERT/UPDATE/DELETE)

### Diagram Flow

Production Application ‚Üí Writes/Reads ‚Üí Master DB (M)
                                          ‚Üì (Async Replication)
Reporting Application ‚Üí Read-only queries ‚Üí Read Replica (R)

---

## RDS Read Replicas ‚Äî Network Cost

**üí° One-liner:** Read replication within the same region is free; cross-region replication costs money.

### Details

- When replication happens **within the same region**, even if it's cross-AZ, there is **no additional network charge**
- When replication is **cross-region**, AWS charges data transfer cost

### Cost Summary

| Replication Type | Network Cost |
|------------------|--------------|
| Same region (even cross-AZ) | ‚úÖ **FREE** |
| Cross-region (e.g., us-east ‚Üí eu-west) | ‚ùå **CHARGES apply** |

---

## RDS Multi-AZ (Disaster Recovery)

Multi-AZ provides **high availability** using **synchronous replication**. It is **not used for scaling**.

**üí° One-liner:** Multi-AZ is for high availability (not read scalability).

### Details

- RDS Multi-AZ uses **SYNC replication** ‚Äî data is written to both primary and standby at the same time
- There is **one DNS endpoint**, AWS automatically redirects traffic if primary fails
- Multi-AZ protects against:
  - AZ failure
  - Storage failure
  - Network failure
  - Instance failure
- **No application change** or manual intervention required

### Diagram Flow

Master DB (AZ-A) ‚Üê‚Üí Standby DB (AZ-B)
      ‚Üì (Sync Replication)
If Master fails ‚Üí DNS automatically switches to Standby

---

## RDS ‚Äî From Single-AZ to Multi-AZ

**üí° One-liner:** Switching to Multi-AZ is zero-downtime and fully automated by AWS.

### Details

When switching, AWS internally:

1. Takes a **snapshot** of the existing DB
2. **Restores** it in a new AZ as a standby
3. Enables **synchronous replication** between them

### Process Flow

Master DB ‚Üí Snapshot ‚Üí Restore in new AZ ‚Üí Sync replication established

---

## RDS Custom

RDS Custom gives full OS and DB-level administrative access ‚Äî ideal for Oracle and SQL Server customizations.

**üí° One-liner:** RDS Custom = full admin access to DB + underlying OS.

### Details

- Supported for **Oracle** and **Microsoft SQL Server**
- Unlike standard RDS where AWS manages the OS, here you can customize the DB and OS:
  - Install patches
  - Configure OS settings
  - Enable native DB features
  - SSH/SSM into the underlying EC2 instance
- Before customization, you **disable automation mode**, because automation may overwrite your changes
- AWS recommends taking a **snapshot** before making changes

### Comparison

| Feature | Standard RDS | RDS Custom |
|---------|--------------|------------|
| **OS Management** | AWS manages | You manage (full access) |
| **DB Management** | AWS manages | You manage (full access) |

---

# Amazon Aurora

## Overview

Aurora is a **fully managed relational database engine** provided by AWS under the RDS service. It is compatible with **MySQL** and **PostgreSQL**, which means applications built for these engines can work with Aurora without modification.

### Performance

Aurora is designed for **high performance and scalability**:
- Up to **5√ó better performance** than standard MySQL
- Up to **3√ó better performance** than PostgreSQL

### Architecture

**It separates compute and storage:**
- **Compute** = DB instances
- **Storage** = Distributed storage system managed by Aurora

This design enables Aurora to handle workloads more efficiently than traditional RDS databases.

---

## Aurora Storage & Replication

### Detailed Explanation

Aurora uses a **distributed, fault-tolerant storage system**:
- Automatically replicates data **6 times** across **3 Availability Zones** (2 copies per AZ)
- If one storage node or even an entire AZ fails, Aurora keeps functioning without data loss
- Storage automatically grows when needed:
  - Starts at **10 GB**
  - Expands up to **128 TB**
  - No manual intervention required

### Diagram Flow

Application ‚Üí Writer node ‚Üí Aurora Storage (replicated 6x across 3 AZs)
           ‚Üí Read replicas access same shared storage

**This architecture eliminates replication lag and improves failover time.**

---

## Aurora vs RDS (Performance + Replicas)

### Detailed Explanation

Aurora improves performance and scaling by separating read and write operations:
- A **writer instance** handles all write operations
- **Read replicas** (up to 15) handle read queries to reduce load from the writer

### Key Benefits

- Failover is **extremely fast** ‚Äî if the writer fails, Aurora promotes a replica to become the new writer in seconds
- Unlike traditional RDS, Aurora replicas don't need independent storage copies; they share the same storage volume
- That removes replication overhead and eliminates lag

---

## Aurora Endpoints

Aurora provides multiple endpoints to simplify application integration:

| Endpoint Type | What it does |
|---------------|--------------|
| **Cluster Endpoint** | Always points to the current writer instance |
| **Reader Endpoint** | Load balances connections across read replicas |
| **Instance Endpoint** | Points to a specific Aurora instance |

**Benefit:** Your application doesn't need to change database connection strings when failover happens.

### Diagram Flow

Application ‚Üí Cluster Endpoint ‚Üí Writer Instance
           ‚Üí Reader Endpoint ‚Üí Load balanced across Read Replicas
           ‚Üí Instance Endpoint ‚Üí Specific instance

---

## Aurora Serverless v2

### Detailed Explanation

Aurora Serverless v2 is a **pay-per-use database model** where the database automatically scales compute resources based on traffic. You don't need to choose instance sizes ‚Äî Aurora automatically adjusts capacity in small increments.

### Benefits

- ‚úÖ **Auto-scaling** (up and down)
- ‚úÖ **No manual provisioning**
- ‚úÖ Only billed for current capacity in **Aurora Capacity Units (ACUs)**

**Ideal for:**
- Unpredictable workloads
- Development environments where load varies significantly

---

## Aurora Global Database

Aurora Global Database allows you to replicate your Aurora cluster to different AWS regions. The replication is designed to be very fast (**<1 second lag**) using dedicated infrastructure separate from your application traffic.

### Use Cases

- ‚úÖ **Disaster recovery** (if one region fails, another becomes primary)
- ‚úÖ **Low-latency reads** for global users

### Diagram Flow

Region A (Writer) ‚Üí Fast replication (<1s lag) ‚Üí Region B (Read-only replicas)
                  ‚Üí Local users read from nearest region (reduced latency)

---

## Aurora Backtrack

Aurora Backtrack lets you **rewind the database** to a previous point in time within seconds, without restoring snapshots or backups.

### Details

- ‚úÖ Useful for accidental data changes (like a bad DELETE statement)
- ‚úÖ Backtrack rewinds the **DB cluster**, not individual tables
- ‚úÖ Fast recovery without full restore

---

## Aurora Machine Learning

Aurora Machine Learning allows you to run **machine-learning predictions** directly from SQL queries inside Aurora.

### How It Works

Instead of moving your data to a ML service, Aurora:
1. Sends your data securely to **Amazon SageMaker** or **Amazon Comprehend**
2. Gets the predictions
3. Returns them as part of your SQL query

### Example SQL

SELECT predict_recommendation(user_id) FROM users;

### Diagram Flow

Application ‚Üí SQL query ‚Üí Aurora
Aurora ‚Üí Sends data ‚Üí SageMaker/Comprehend
SageMaker/Comprehend ‚Üí Returns predictions ‚Üí Aurora
Aurora ‚Üí Returns SQL result with predictions ‚Üí Application

**üí° One-liner:** Aurora lets you run machine learning predictions directly through SQL using SageMaker and Comprehend.

---

## Babelfish for Aurora PostgreSQL

Babelfish makes Aurora PostgreSQL understand **T-SQL commands** (SQL Server dialect).

### How It Works

- SQL Server applications can connect and work with Aurora PostgreSQL with **little to no code changes**
- The application still thinks it's talking to SQL Server
- During migration, **AWS SCT + DMS** can migrate the database from SQL Server to Aurora PostgreSQL

### Diagram Flow

SQL Server Application ‚Üí T-SQL queries ‚Üí Babelfish ‚Üí Aurora PostgreSQL
PostgreSQL Application ‚Üí Native queries ‚Üí Aurora PostgreSQL

**üí° One-liner:** Run SQL Server applications on Aurora PostgreSQL without rewriting queries using T-SQL compatibility.

---

# RDS & Aurora Backups

## RDS Backups

RDS provides backup features to protect your database.

### Automated Backups

- RDS automatically performs a **daily full backup**
- **Transaction logs** are backed up every **5 minutes**
- You can restore the database to **any point in time** (from oldest backup to ~5 minutes ago)
- **Retention:** 1 to 35 days (can be set to 0 to disable)

### Manual Snapshots

- You manually initiate them
- Snapshots are retained **indefinitely** until you delete them

### üí∞ Important Trick

If you stop an RDS database, you still pay for storage. If it's long term, **snapshot + restore later is cheaper**.

**üí° One-liner:** RDS provides automated backups + manual snapshots, and supports point-in-time recovery.

---

## Aurora Backups

Works similarly to RDS, but with key differences:

- ‚úÖ Aurora backups **cannot be disabled**
- ‚úÖ Retention window is **1‚Äì35 days**
- ‚úÖ Supports **point-in-time recovery**
- ‚úÖ Manual snapshots are also supported and retained as long as you want

**üí° One-liner:** Aurora always has automated backups enabled, supporting point-in-time recovery.

---

## RDS & Aurora Restore Options

When restoring from backup or snapshot, AWS creates a **new database instance**.

### Restoring MySQL RDS from S3

1. Export backup from on-prem database
2. Upload backup to **S3**
3. Restore backup to a **new MySQL RDS instance**

### Restoring MySQL Aurora cluster from S3

1. Backup taken using **Percona XtraBackup**
2. Uploaded to **S3**
3. Restored into a **new Aurora cluster**

**üí° One-liner:** Backups from S3 can restore new MySQL RDS or Aurora environments.

---

## Aurora Database Cloning

Aurora supports creating a new DB cluster from an existing one **almost instantly** using **copy-on-write**.

### How Copy-on-Write Works

1. Initially, **cloned DB shares the same storage** as the production database
2. Only when data is **modified** does Aurora duplicate the changed data
3. This makes cloning very **fast and cost-efficient**

### Diagram

Production Aurora ‚Üí Clone ‚Üí Staging Aurora DB
                  ‚Üì (minimal storage cost)
           Shared storage until modified

**üí° One-liner:** Aurora cloning creates fast, cost-effective copies of databases using copy-on-write.

---

# RDS & Aurora Security

## Security Features

Security features provided by both RDS and Aurora:

### At-rest Encryption

- Data stored on disks (including replicas) is encrypted using **AWS KMS**
- Encryption must be enabled at **DB creation**; replicas inherit encryption status
- To encrypt an existing unencrypted DB: **snapshot ‚Üí restore with encryption**

### In-flight Encryption

- **TLS** used for encrypted DB connections

### IAM Authentication

- Connect to DB using **IAM roles** rather than usernames/passwords

### Network Security

- **Security Groups** control network access

### SSH Access

- ‚ùå **Not allowed**, except **RDS Custom**

### Audit Logs

- Can be streamed to **CloudWatch** for compliance & retention

**üí° One-liner:** RDS and Aurora support encryption, IAM authentication, security groups, and audit logging.

---

## Amazon RDS Proxy

RDS Proxy is a **fully managed database connection pooling service**.

### What It Does

- Applications **share database connections** instead of opening new ones repeatedly
- Improves DB efficiency and reduces load (fewer open connections)
- Reduces **failover time by up to 66%**
- Supports RDS (MySQL, PostgreSQL, MariaDB, SQL Server) and Aurora (MySQL, PostgreSQL)
- **IAM Authentication** + **Secrets Manager** integration for secure access

### Diagram Flow

Lambda functions ‚Üí RDS Proxy ‚Üí Manages connections ‚Üí DB instance
                              ‚Üì (inside VPC subnet)
                    Not publicly accessible

**üí° One-liner:** RDS Proxy manages DB connections, speeds failover, and improves database efficiency.

---

# Amazon ElastiCache

## Overview

- **Amazon ElastiCache** is a managed caching service from AWS that provides fully managed **Redis** or **Memcached** environments
- It acts similarly to how RDS offers managed relational databases ‚Äî ElastiCache offers **managed in-memory data stores** for high-performance, low-latency applications
- Caches store frequently accessed data **in-memory** to drastically improve application response times and reduce the load on backend databases (like RDS)
- This is especially beneficial for **read-intensive workloads** such as APIs, gaming, or analytics dashboards
- ElastiCache also helps applications become **stateless** by offloading user session data or temporary states to the cache
- Since it's a **managed AWS service**, it handles all OS patching, maintenance, scaling, configuration, monitoring, backups, and recovery
- However, using ElastiCache often requires **significant code changes** in the application to integrate caching logic

---

## ElastiCache Solution Architecture ‚Äì User Session Store

In a distributed or load-balanced application, user session management can be complex. ElastiCache simplifies this by acting as a **shared session store**.

### How It Works

1. When a user logs in, the application writes **session data** (like user tokens or preferences) to ElastiCache
2. If the same user connects later through a different application instance, that instance retrieves session data from ElastiCache
3. Ensures the user remains logged in seamlessly

### Diagram Flow

User ‚Üí Multiple Application Instances
     ‚Üì
Each instance reads/writes sessions from central ElastiCache cluster
     ‚Üì
Consistent session states across all servers

**This architecture enables stateless web servers** ‚Äî all session data is centralized in the cache.

---

## ElastiCache ‚Äì Redis vs Memcached

| Feature | Redis | Memcached |
|---------|-------|-----------|
| **High Availability** | ‚úÖ Multi-AZ with Auto-Failover | ‚ùå No replication |
| **Read Replicas** | ‚úÖ Yes (scale read operations) | ‚ùå No |
| **Data Durability** | ‚úÖ AOF (Append Only File) persistence | ‚ùå Non-persistent |
| **Backup & Restore** | ‚úÖ Yes | ‚úÖ Serverless backup/restore |
| **Data Structures** | ‚úÖ Advanced (sets, sorted sets) | ‚ùå Simple key-value |
| **Architecture** | Single-threaded | Multi-threaded |
| **Replication** | ‚úÖ Yes | ‚ùå No |
| **Sharding** | ‚ùå No | ‚úÖ Yes (data partitioning) |

### Diagram Concept

- **Redis:** Uses replication between nodes for fault tolerance
- **Memcached:** Distributes data across nodes using sharding

---

## ElastiCache ‚Äì Cache Security

Security in ElastiCache involves both IAM and engine-specific mechanisms:

### IAM Authentication for Redis

- Allows using IAM roles for access control to the cluster
- IAM policies are used only for **AWS API-level access**, not for data access

### Redis AUTH

- Configure a password or token for additional cache-level security
- Supports **SSL encryption in transit**, securing client-to-cache communication

### Memcached

- Uses **SASL-based authentication** for advanced user validation

### Diagram Flow

EC2 Client ‚Üê‚Üí SSL encrypted channel ‚Üê‚Üí Redis
              ‚Üì
        Redis AUTH + Security Groups

---

## Patterns for ElastiCache

Three main caching patterns are used in applications:

### 1. Lazy Loading

- Data is cached **only when first requested** (on a cache miss)
- ‚úÖ Reduces unnecessary caching
- ‚ùå Can lead to stale data if the source DB changes and cache isn't updated

### 2. Write Through

- Data is written to **cache and DB simultaneously**
- ‚úÖ Ensures cache always has fresh data
- ‚ùå Adds a bit of write latency

### 3. Session Store

- Stores **temporary user session data** (with TTLs) in the cache
- ‚úÖ Maintains lightweight, stateless applications

### Diagram Flow

Application ‚Üê‚Üí ElastiCache ‚Üê‚Üí RDS
            ‚Üì
    Cache hits, misses, reads, and writes

---

## ElastiCache ‚Äì Redis Use Case

### Gaming Leaderboards

This highlights a real-world use case ‚Äî **Gaming Leaderboards**.

### Why Redis?

- Leaderboards need to store player rankings that constantly update as players score points
- **Redis Sorted Sets** are ideal because they maintain both **uniqueness** and **order** automatically

### How It Works

Whenever a new score is added:
1. Redis instantly reorders the leaderboard based on the updated scores
2. Provides a **real-time ranking system** that updates dynamically

### Diagram Flow

Multiple clients (players) ‚Üí Sending score updates
                           ‚Üì
            ElastiCache for Redis processes updates
                           ‚Üì
            Maintains sorted leaderboard (real-time)
                           ‚Üì
            Updated leaderboard instantly available to all players

---

## Summary

| Service | Type | Best For |
|---------|------|----------|
| **RDS** | Managed SQL DB | Traditional relational databases |
| **Aurora** | AWS-optimized DB | High-performance MySQL/PostgreSQL (5x-3x faster) |
| **Aurora Serverless** | Auto-scaling DB | Variable/unpredictable workloads |
| **Aurora Global** | Multi-region DB | Disaster recovery, global low latency |
| **RDS Proxy** | Connection pooler | Reduce DB load, improve failover |
| **ElastiCache Redis** | In-memory cache | High availability, complex data structures, leaderboards |
| **ElastiCache Memcached** | In-memory cache | Simple caching, sharding, multi-threaded |

---

**üìù Note:** This content is optimized for AWS Solutions Architect certification exam preparation.
